{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f2b779-fcd8-42ed-adaf-1b824f6b9eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason/Purpose</th>\n",
       "      <th>Status Reason</th>\n",
       "      <th>Priority</th>\n",
       "      <th>CRM Type</th>\n",
       "      <th>Type Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "      <td>Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amount not Credited</td>\n",
       "      <td>Valid Case - Refund Approved/ ŸÖŸàÿßŸÅŸÇÿ© ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Amount not Credited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rain Issue</td>\n",
       "      <td>Valid Request/ÿ∑ŸÑÿ® ÿµÿ≠Ÿäÿ≠</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Request</td>\n",
       "      <td>Service Enhancement Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amount not Credited</td>\n",
       "      <td>Valid 12aed approved by AMCE</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Amount not Credited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Passengers Inspection and Control</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Request</td>\n",
       "      <td>Passengers Inspection and Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "      <td>Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Staff Conduct</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Staff Conduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>Not Giving The Right Money Change</td>\n",
       "      <td>Invalid Complaint/ÿ¥ŸÉŸàŸâ ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠ÿ©</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Not Giving The Right Money Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>Amount not Credited</td>\n",
       "      <td>Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Amount not Credited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "      <td>Invalid Complaint/ÿ¥ŸÉŸàŸâ ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠ÿ©</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Wrong Product Selection or Loading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1788 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Reason/Purpose   \\\n",
       "0     Wrong Product Selection or Loading   \n",
       "1                    Amount not Credited   \n",
       "2                             Rain Issue   \n",
       "3                    Amount not Credited   \n",
       "4      Passengers Inspection and Control   \n",
       "...                                  ...   \n",
       "1783  Wrong Product Selection or Loading   \n",
       "1784                       Staff Conduct   \n",
       "1785   Not Giving The Right Money Change   \n",
       "1786                 Amount not Credited   \n",
       "1787  Wrong Product Selection or Loading   \n",
       "\n",
       "                                         Status Reason  Priority     CRM Type  \\\n",
       "0                            Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©  Normal    Complaint    \n",
       "1     Valid Case - Refund Approved/ ŸÖŸàÿßŸÅŸÇÿ© ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™...  Normal    Complaint    \n",
       "2                                Valid Request/ÿ∑ŸÑÿ® ÿµÿ≠Ÿäÿ≠  Normal      Request    \n",
       "3                          Valid 12aed approved by AMCE  Normal    Complaint    \n",
       "4                                               Invalid  Normal      Request    \n",
       "...                                                 ...      ...          ...   \n",
       "1783                         Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©  Normal    Complaint    \n",
       "1784                                              Valid  Normal    Complaint    \n",
       "1785                   Invalid Complaint/ÿ¥ŸÉŸàŸâ ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠ÿ©  Normal    Complaint    \n",
       "1786                         Valid Complaint/ÿ¥ŸÉŸàŸâ ÿµÿ≠Ÿäÿ≠ÿ©  Normal    Complaint    \n",
       "1787                   Invalid Complaint/ÿ¥ŸÉŸàŸâ ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠ÿ©  Normal    Complaint    \n",
       "\n",
       "                         Type Description  \n",
       "0      Wrong Product Selection or Loading  \n",
       "1                     Amount not Credited  \n",
       "2             Service Enhancement Request  \n",
       "3                     Amount not Credited  \n",
       "4       Passengers Inspection and Control  \n",
       "...                                   ...  \n",
       "1783   Wrong Product Selection or Loading  \n",
       "1784                        Staff Conduct  \n",
       "1785    Not Giving The Right Money Change  \n",
       "1786                  Amount not Credited  \n",
       "1787   Wrong Product Selection or Loading  \n",
       "\n",
       "[1788 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Sample 1.xlsx')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d41553-1f8f-4f7f-9302-033835bb1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['CRM Type']\n",
    "y = df['Type Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb47034-f1d2-4680-9ba3-d12c248d2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression with CountVectorizer\n",
      "0.36685288640595903\n",
      "Confusion matrix is not 2x2, multi-class classification detected.\n",
      "Classification Report:\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                       Activation Delay       0.00      0.00      0.00        13\n",
      "                Airconditioning Problem       0.00      0.00      0.00         9\n",
      "                    Amount not Credited       0.31      0.99      0.47       135\n",
      "                           Appreciation       1.00      1.00      1.00        10\n",
      "                       Defected Product       0.00      0.00      0.00         4\n",
      "                        Delayed Service       0.00      0.00      0.00         1\n",
      "                            Doors Issue       0.00      0.00      0.00         1\n",
      "                         Fine Objection       0.00      0.00      0.00        60\n",
      "                 Items Dropped On Track       0.56      0.83      0.67         6\n",
      "                    Lack of cleanliness       0.00      0.00      0.00         3\n",
      "                        Metro  Schedule       0.00      0.00      0.00         1\n",
      "                            Money Stuck       0.00      0.00      0.00         5\n",
      "                    Noise and Vibration       0.00      0.00      0.00         1\n",
      "       Nol Card or Ticket Not Dispensed       0.00      0.00      0.00         2\n",
      "      Not Giving The Right Money Change       0.00      0.00      0.00        32\n",
      "                         Out Of Service       0.00      0.00      0.00         3\n",
      "                             Overcharge       0.00      0.00      0.00        49\n",
      "                           Overcrowding       0.00      0.00      0.00         1\n",
      "      Passengers Inspection and Control       0.00      0.00      0.00        29\n",
      "             Refusal of Payment by Card       0.00      0.00      0.00         2\n",
      "          Reverse Wrong Payment Request       0.00      0.00      0.00         3\n",
      " Safety and Security Around The Station       0.00      0.00      0.00         2\n",
      "            Service Enhancement Request       0.57      0.98      0.72        49\n",
      "                          Staff Conduct       0.00      0.00      0.00        61\n",
      "                   Staff Unavailability       0.00      0.00      0.00         2\n",
      "              Technical Support Request       0.00      0.00      0.00         2\n",
      "               Travel Pass Fare Related       0.00      0.00      0.00         2\n",
      "                       Unpleasant Smell       0.00      0.00      0.00         1\n",
      "     Wrong Product Selection or Loading       0.00      0.00      0.00        48\n",
      "\n",
      "                               accuracy                           0.37       537\n",
      "                              macro avg       0.08      0.13      0.10       537\n",
      "                           weighted avg       0.15      0.37      0.21       537\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total Positives (across all classes): 537\n",
      "Total Negatives (across all classes): 15036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                        test_size = 0.3, random_state=42)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "#Vectorizing the text data\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Training the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ctmTr, y_train)\n",
    "#Accuracy score\n",
    "lr_score = lr.score(X_test_dtm, y_test)\n",
    "print(\"Results for Logistic Regression with CountVectorizer\")\n",
    "print(lr_score)\n",
    "#Predicting the labels for test data\n",
    "y_pred_lr = lr.predict(X_test_dtm)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "# Print the confusion matrix and its shape\n",
    "# print(\"Confusion Matrix:\\n\", cm_lr)\n",
    "# print(\"Shape:\", cm_lr.shape)\n",
    "\n",
    "# Case 1: Binary Classification (2x2 confusion matrix)\n",
    "if cm_lr.shape == (2, 2):\n",
    "    tn, fp, fn, tp = cm_lr.ravel()  # Unpack the confusion matrix into tn, fp, fn, tp\n",
    "    print(\"TN:\", tn, \"FP:\", fp, \"FN:\", fn, \"TP:\", tp)\n",
    "\n",
    "    # Compute True Positive Rate (TPR) and True Negative Rate (TNR)\n",
    "    tpr_lr = round(tp / (tp + fn), 4)  # Sensitivity or Recall\n",
    "    tnr_lr = round(tn / (tn + fp), 4)  # Specificity\n",
    "\n",
    "    print(\"TPR (Recall):\", tpr_lr)\n",
    "    print(\"TNR (Specificity):\", tnr_lr)\n",
    "\n",
    "    # Additional Analysis: Identifying positive and negative values\n",
    "    print(\"\\n** Binary Classification - Positive vs Negative Analysis **\")\n",
    "    # Positive class: tp (True Positives), fn (False Negatives)\n",
    "    # Negative class: tn (True Negatives), fp (False Positives)\n",
    "    \n",
    "    # True Positives: Correctly predicted positives\n",
    "    print(f\"True Positives (Correctly predicted as positive): {tp}\")\n",
    "    # False Negatives: Actual positives that were predicted as negative\n",
    "    print(f\"False Negatives (Actual positives predicted as negative): {fn}\")\n",
    "    \n",
    "    # True Negatives: Correctly predicted negatives\n",
    "    print(f\"True Negatives (Correctly predicted as negative): {tn}\")\n",
    "    # False Positives: Actual negatives predicted as positive\n",
    "    print(f\"False Positives (Actual negatives predicted as positive): {fp}\")\n",
    "\n",
    "    # ** Total Positives and Negatives (Binary) **\n",
    "    total_positive = tp + fn  # Total number of actual positive instances\n",
    "    total_negative = tn + fp  # Total number of actual negative instances\n",
    "\n",
    "    print(f\"\\nTotal Positives: {total_positive}\")\n",
    "    print(f\"Total Negatives: {total_negative}\")\n",
    "\n",
    "# Case 2: Multi-Class Classification (NxN confusion matrix)\n",
    "else:\n",
    "    print(\"Confusion matrix is not 2x2, multi-class classification detected.\")\n",
    "    \n",
    "    # Print classification report with precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "    # Additional Analysis: For multi-class, iterate over each class\n",
    "    # print(\"\\n** Multi-Class Classification - Positive vs Negative Analysis **\")\n",
    "    classes = cm_lr.shape[0]  # Get the number of classes\n",
    "\n",
    "    total_positive = 0  # To store the total positive values across all classes\n",
    "    total_negative = 0  # To store the total negative values across all classes\n",
    "\n",
    "    for i in range(classes):\n",
    "        # print(f\"Class {i}:\")\n",
    "        # True Positives (TP) for each class\n",
    "        tp = cm_lr[i, i]\n",
    "        # False Negatives (FN) for each class (sum of the column, excluding the diagonal)\n",
    "        fn = cm_lr[i, :].sum() - tp\n",
    "        # False Positives (FP) for each class (sum of the row, excluding the diagonal)\n",
    "        fp = cm_lr[:, i].sum() - tp\n",
    "        # True Negatives (TN) for each class (sum of all other cells excluding the row and column of the class)\n",
    "        tn = cm_lr.sum() - (cm_lr[i, :].sum() + cm_lr[:, i].sum()) + tp\n",
    "        \n",
    "        # Display the positive vs negative analysis for each class\n",
    "        # print(f\"  True Positives (TP) for Class {i}: {tp}\")\n",
    "        # print(f\"  False Negatives (FN) for Class {i}: {fn}\")\n",
    "        # print(f\"  True Negatives (TN) for Class {i}: {tn}\")\n",
    "        # print(f\"  False Positives (FP) for Class {i}: {fp}\")\n",
    "        \n",
    "        # Add to the total positives and negatives\n",
    "        total_positive += tp + fn\n",
    "        total_negative += tn + fp\n",
    "\n",
    "        print()\n",
    "\n",
    "    # ** Total Positives and Negatives (Multi-Class) **\n",
    "    print(f\"\\nTotal Positives (across all classes): {total_positive}\")\n",
    "    print(f\"Total Negatives (across all classes): {total_negative}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec8efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Dell\\OneDrive - @SNC\\Desktop\\sentiment analysis\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_18456\\3863803845.py:78: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [237/237 2:08:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.298200</td>\n",
       "      <td>3.084559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.628700</td>\n",
       "      <td>2.354743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.117500</td>\n",
       "      <td>2.111913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36685288640595903\n",
      "Confusion Matrix:\n",
      " [[  0   0  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  60   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  49   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  28   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   3   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  48   0   0   0   0   0   0]\n",
      " [  0   0  61   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  48   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Confusion matrix is not 2x2, multi-class classification detected.\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.31      0.99      0.47       135\n",
      "           4       1.00      1.00      1.00        10\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00        60\n",
      "          11       0.56      0.83      0.67         6\n",
      "          15       0.00      0.00      0.00         3\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00        32\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00        49\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00        29\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         3\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.57      0.98      0.72        49\n",
      "          37       0.00      0.00      0.00        61\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.37       537\n",
      "   macro avg       0.08      0.13      0.10       537\n",
      "weighted avg       0.15      0.37      0.21       537\n",
      "\n",
      "\n",
      "Total Positives (across all classes): 537\n",
      "Total Negatives (across all classes): 15036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\OneDrive - @SNC\\Desktop\\sentiment analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Dell\\OneDrive - @SNC\\Desktop\\sentiment analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Dell\\OneDrive - @SNC\\Desktop\\sentiment analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder  # Added to handle label encoding\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Sample 1.xlsx')\n",
    "X = df['CRM Type']\n",
    "y = df['Type Description']\n",
    "\n",
    "# Encode the labels (strings to integers)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create a custom Dataset class to handle BERT input\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)  # Correct data type for label\n",
    "        }\n",
    "\n",
    "# Tokenizing the data\n",
    "train_dataset = TextDataset(X_train.values, y_train, tokenizer)\n",
    "test_dataset = TextDataset(X_test.values, y_test, tokenizer)\n",
    "\n",
    "# Define the BERT model for classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(np.unique(y_encoded)))\n",
    "\n",
    "# Trainer setup with custom arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred_bert = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred_bert)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_bert = confusion_matrix(y_test, y_pred_bert)\n",
    "print(\"Confusion Matrix:\\n\", cm_bert)\n",
    "\n",
    "# For binary classification\n",
    "if cm_bert.shape == (2, 2):\n",
    "    tn, fp, fn, tp = cm_bert.ravel()  # Unpack the confusion matrix into tn, fp, fn, tp\n",
    "    print(\"TN:\", tn, \"FP:\", fp, \"FN:\", fn, \"TP:\", tp)\n",
    "\n",
    "    # Compute True Positive Rate (TPR) and True Negative Rate (TNR)\n",
    "    tpr_bert = round(tp / (tp + fn), 4)  # Sensitivity or Recall\n",
    "    tnr_bert = round(tn / (tn + fp), 4)  # Specificity\n",
    "\n",
    "    print(\"TPR (Recall):\", tpr_bert)\n",
    "    print(\"TNR (Specificity):\", tnr_bert)\n",
    "\n",
    "    # Additional Analysis: Identifying positive and negative values\n",
    "    print(\"\\n** Binary Classification - Positive vs Negative Analysis **\")\n",
    "    print(f\"True Positives (Correctly predicted as positive): {tp}\")\n",
    "    print(f\"False Negatives (Actual positives predicted as negative): {fn}\")\n",
    "    print(f\"True Negatives (Correctly predicted as negative): {tn}\")\n",
    "    print(f\"False Positives (Actual negatives predicted as positive): {fp}\")\n",
    "\n",
    "    total_positive = tp + fn  # Total number of actual positive instances\n",
    "    total_negative = tn + fp  # Total number of actual negative instances\n",
    "\n",
    "    print(f\"\\nTotal Positives: {total_positive}\")\n",
    "    print(f\"Total Negatives: {total_negative}\")\n",
    "\n",
    "# For multi-class classification\n",
    "else:\n",
    "    print(\"Confusion matrix is not 2x2, multi-class classification detected.\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bert))\n",
    "\n",
    "    # Additional Analysis for multi-class\n",
    "    total_positive = 0\n",
    "    total_negative = 0\n",
    "\n",
    "    for i in range(cm_bert.shape[0]):\n",
    "        tp = cm_bert[i, i]\n",
    "        fn = cm_bert[i, :].sum() - tp\n",
    "        fp = cm_bert[:, i].sum() - tp\n",
    "        tn = cm_bert.sum() - (cm_bert[i, :].sum() + cm_bert[:, i].sum()) + tp\n",
    "        \n",
    "        total_positive += tp + fn\n",
    "        total_negative += tn + fp\n",
    "\n",
    "    print(f\"\\nTotal Positives (across all classes): {total_positive}\")\n",
    "    print(f\"Total Negatives (across all classes): {total_negative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270af9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
